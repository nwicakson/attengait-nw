{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASIA-B\n",
    "\n",
    "0. Data preparation\n",
    "\n",
    "    Download the CASIA-B dataset from http://www.cbsr.ia.ac.cn/english/Gait%20Databases.asp and extract the files. Raw RGB frames and silhouettes are required. Then, run the following code to prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 preprocessing/pretreatment_casiab_of.py --input_path ./data/casiab/silhouettes --input_path_rgb ./data/casiab/rgb --output_path ./data/casiab/of --sum_sil=10000 --worker_num=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 preprocessing/generate_of_dataset_casiab.py --ofdir ./data/casiab/of --outdir ./data/casiab/ofdataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 preprocessing/generate_of_dataset_casiab_test.py --ofdir ./data/casiab/of --outdir ./data/casiab/ofdataset/ --mode ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python3 preprocessing/generate_of_dataset_casiab_test.py --ofdir ./data/casiab/of --outdir ./data/casiab/ofdataset/ --mode test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python3 mains/train.py --datadir=./data/casiab/ofdataset/ --experdir=./exp/ \\\n",
    "    --nclasses=74 --epochs=8000 --extraepochs=1000 --bs=16 --lr=0.0005 \\\n",
    "    --attention_drop_rate=0.1 --softmax_attention --kernel_regularizer \\\n",
    "    --prefix=attengait_casiab --lr_sched --cross_weight=1.0 --model_size=tiny \\\n",
    "    --split_crossentropy --combined_output_length=32 --multi_gpu=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python3 mains/train.py --datadir=../ofdataset/ --experdir=../ofoutput \\\n",
    "    --nclasses=74 --epochs=8000 --extraepochs=1000 --bs=100 --pk --p 8 --k 8 --lr=0.0005 \\\n",
    "    --attention_drop_rate=0.1 --softmax_attention --kernel_regularizer \\\n",
    "    --prefix=attengait_casiab --lr_sched --cross_weight=1.0 \\\n",
    "    --split_crossentropy --combined_output_length=32 --multi_gpu=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python3 mains/test.py --datadir=./data/casiab/ofdataset/ --knn 1 --nclasses 50 --allcameras --model EXPERPATH/EXPERFOLDER/model-final.hdf5 --bs 1 --cross_weight=1.0 --split_crossentropy --softmax_attention --combined_output_length=32"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
